{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<table align=\"center\">\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/andrew-nash/CS6421-labs/blob/main/Lab7.ipynb\">\n",
        "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/andrew-nash/CS6421-labs/blob/main/Lab7.ipynb\">\n",
        "        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
        "</table>\n",
        "\n",
        "# Anomaly Detection Autoencoders\n",
        "\n",
        "Source: https://www.tensorflow.org/tutorials/generative/autoencoder#third_example_anomaly_detection\n",
        "\n",
        "In this lab we will look at modelling non-image data with autoencoders - specifically, we will be taking ECG (Electrocardiogram) signals, and uing an autoencoder to identify potential abnormalities in the signals"
      ],
      "metadata": {
        "id": "jaVLE7rzCgmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "sOC-7TY7DqsW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Data\n",
        "\n",
        "We will be using the [ECG5000 Dataset](http://www.timeseriesclassification.com/description.php?Dataset=ECG5000). This countains 5000 ECG signals each of 140 samples. Each signal has a label indicating whether it contains normal or abnormal behaviour."
      ],
      "metadata": {
        "id": "r1sxfCuiDJnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_csv('http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv', header=None)\n",
        "raw_data = dataframe.values\n",
        "dataframe.head()"
      ],
      "metadata": {
        "id": "rQ-YL3XmCgM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "R-kBp5s9CULQ"
      },
      "outputs": [],
      "source": [
        "# The last element contains the labels\n",
        "labels = raw_data[:, -1]\n",
        "\n",
        "# The other data points are the electrocadriogram data\n",
        "data = raw_data[:, 0:-1]\n",
        "\n",
        "train_data, valid_data, train_labels, valid_labels = train_test_split(\n",
        "    data, labels, test_size=0.2, random_state=21\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "4u8ZJdGpEJGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only pre-processing needed will be to scalem the data to be between 0 and 1"
      ],
      "metadata": {
        "id": "hbH69qWtD0Xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_val = tf.reduce_min(train_data)\n",
        "max_val = tf.reduce_max(train_data)\n",
        "\n",
        "train_data = (train_data - min_val) / (max_val - min_val)\n",
        "valid_data = (valid_data - min_val) / (max_val - min_val)\n",
        "\n",
        "train_data = tf.cast(train_data, tf.float32)\n",
        "valid_data = tf.cast(valid_data, tf.float32)"
      ],
      "metadata": {
        "id": "HFcrJEJSDxQb"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the 1s and 0s to True/False\n",
        "train_labels = train_labels.astype(bool)\n",
        "valid_labels = valid_labels.astype(bool)\n",
        "\n",
        "# use a handy trick of numpy arrays and tf tensors\n",
        "#    train_data[ [True,False,True,False,False,...] ] will return the values of train_data\n",
        "#                                                    at indices that correspond to True\n",
        "normal_train_data = train_data[train_labels]\n",
        "normal_valid_data = valid_data[valid_labels]\n",
        "\n",
        "anomalous_train_data = train_data[~train_labels]\n",
        "anomalous_valid_data = valid_data[~valid_labels]"
      ],
      "metadata": {
        "id": "OfLIcXsJD6x2"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.grid()\n",
        "plt.plot(np.arange(140), normal_train_data[0])\n",
        "plt.title(\"A Normal ECG\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BYvmbqLTD8TW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.grid()\n",
        "plt.plot(np.arange(140), anomalous_train_data[0])\n",
        "plt.title(\"An Anomalous ECG\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-PRDW9fQEhUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling\n",
        "\n",
        "We are going to approach this problem in what might perhaps be a surprising manner.\n",
        "\n",
        "We will **not** fit a regression/classification deep model onto the data directly.\n",
        "\n",
        "Instead, we will fit an autoecnoder to the signals and attempt to reconstruct its inputs.\n",
        "\n",
        "This can be considered to be a model that tries as best as possible to learn a *\"normal\"* model of ECG signal behaviour. Then, we will compare the *actual* signals, to their reconstruction - our assumption is that deviations from the reconstructions are caused by anomalous behavior.\n",
        "\n",
        "<strong>What is the benefit of this over a more traditional approach?</strong>"
      ],
      "metadata": {
        "id": "c5ruJt_BEnoz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the reconstruction autoencoder model"
      ],
      "metadata": {
        "id": "JJqh7WbwIGGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir tboard"
      ],
      "metadata": {
        "id": "CMmKTEj-HLAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "twXaJJUaHOOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run_name=\"Dense Autoencoder\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(f\"./tboard/{run_name}\", histogram_freq=1)\n",
        "wandb.init(\n",
        "        project = \"Lab7\",\n",
        "        name =   run_name)\n",
        "\n",
        "class AnomalyDetector(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super(AnomalyDetector, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(8, activation=\"relu\")])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(140, activation=\"sigmoid\")])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = AnomalyDetector()\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='mae')\n",
        "autoencoder.fit(normal_train_data, normal_train_data,\n",
        "          epochs=20,\n",
        "          batch_size=512,\n",
        "          validation_data=(valid_data, valid_data),\n",
        "          shuffle=True, callbacks=[tensorboard_callback,WandbMetricsLogger()])"
      ],
      "metadata": {
        "id": "tx6InqEgG3sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now look at the reconstruction of a normal (non-anaomalous) ECG signal"
      ],
      "metadata": {
        "id": "_BlFqJC9HwmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data = autoencoder.encoder(normal_valid_data).numpy()\n",
        "decoded_data = autoencoder.decoder(encoded_data).numpy()\n",
        "\n",
        "plt.plot(normal_valid_data[0], 'b')\n",
        "plt.plot(decoded_data[0], 'r')\n",
        "plt.fill_between(np.arange(140), decoded_data[0], normal_valid_data[0], color='lightcoral')\n",
        "plt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Clj6FU2NHawN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "... compared to an anomalous signal:"
      ],
      "metadata": {
        "id": "1MSf2S2aH-nX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data = autoencoder.encoder(anomalous_valid_data).numpy()\n",
        "decoded_data = autoencoder.decoder(encoded_data).numpy()\n",
        "\n",
        "plt.plot(anomalous_valid_data[0], 'b')\n",
        "plt.plot(decoded_data[0], 'r')\n",
        "plt.fill_between(np.arange(140), decoded_data[0], anomalous_valid_data[0], color='lightcoral')\n",
        "plt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "krbKEVP9HvZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detecting the anomalies\n",
        "\n",
        "Detect anomalies by calculating whether the reconstruction loss is greater than a fixed threshold. In this tutorial, you will calculate the mean average error for normal examples from the training set, then classify future examples as anomalous if the reconstruction error is higher than one standard deviation from the training set.\n",
        "\n",
        "Plot the reconstruction error on normal ECGs from the training set"
      ],
      "metadata": {
        "id": "RPOAKZHIICIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions = autoencoder.predict(normal_train_data)\n",
        "train_loss = tf.keras.losses.mae(reconstructions, normal_train_data)\n",
        "\n",
        "plt.hist(train_loss[None,:], bins=50)\n",
        "plt.xlabel(\"Train loss\")\n",
        "plt.ylabel(\"No of examples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gF8yCEuHIEK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = np.mean(train_loss) + np.std(train_loss)\n",
        "print(\"Threshold: \", threshold)"
      ],
      "metadata": {
        "id": "8CcuWT06IQrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many heuristics for choosing this threshold.\n",
        "\n",
        "Next, look at the distribution of reconstruction errors for the validation data"
      ],
      "metadata": {
        "id": "C7Zh2zQmIzKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions = autoencoder.predict(anomalous_valid_data)\n",
        "valid_loss = tf.keras.losses.mae(reconstructions, anomalous_valid_data)\n",
        "\n",
        "plt.hist(valid_loss[None, :], bins=50)\n",
        "plt.xlabel(\"Validation loss\")\n",
        "plt.ylabel(\"No of examples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tk1HRno8ITFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, data, threshold):\n",
        "  reconstructions = model(data)\n",
        "  loss = tf.keras.losses.mae(reconstructions, data)\n",
        "  return tf.math.less(loss, threshold)\n",
        "\n",
        "def print_stats(predictions, labels):\n",
        "  print(\"Accuracy = {}\".format(accuracy_score(labels, predictions)))\n",
        "  print(\"Precision = {}\".format(precision_score(labels, predictions)))\n",
        "  print(\"Recall = {}\".format(recall_score(labels, predictions)))"
      ],
      "metadata": {
        "id": "THvIgc4IIZRT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = predict(autoencoder, valid_data, threshold)\n",
        "print_stats(preds, valid_labels)"
      ],
      "metadata": {
        "id": "xjyZFVsoIbpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Autoencoders\n",
        "\n",
        "Now, instead of a Dense model, lets introduce a CNN model and see if we can improve performance.\n",
        "\n",
        "We are working with a time-series vector rather than a 2D image (or rank-3 tensor for a 2D image with multiple colour channels). This means that all of our convolutional kernels will have height of 1. In this case, we could use Conv2D with 1 values for all height hyper-parameters. For simplicity, TensorFlow exposes a Con1D layer that does this for us automatically to make out code cleaner.\n",
        "\n",
        "However, this is onl a wrapper on Conv2D - our data still needs to be converted to a 2D matix (of height 1)"
      ],
      "metadata": {
        "id": "DbCo-R0_JDoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anomalous_train_data_2d = tf.expand_dims(anomalous_train_data, -1)\n",
        "normal_train_data_2d = tf.expand_dims(normal_train_data, -1)\n",
        "valid_data_2d = tf.expand_dims(valid_data, -1)\n",
        "anomalous_valid_data_2d = tf.expand_dims(anomalous_valid_data, -1)\n",
        "normal_valid_data_2d = tf.expand_dims(normal_valid_data, -1)"
      ],
      "metadata": {
        "id": "ABrmr5EYNao3"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run_name=\"CNN Autoencoder\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(f\"./tboard/{run_name}\", histogram_freq=1)\n",
        "#wandb.init(\n",
        "#        project = \"Lab7\",\n",
        "#        name =   run_name)\n",
        "\n",
        "class AnomalyDetector(tf.keras.models.Model):\n",
        "  def __init__(self):\n",
        "    super(AnomalyDetector, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "        # initial dimension is 140\n",
        "      tf.keras.layers.Conv1D(filters=40,kernel_size=64,padding='same',activation=\"relu\", input_shape=(140,1)),\n",
        "      tf.keras.layers.Conv1D(filters=16,kernel_size=32,padding='same',activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPooling1D(2, padding=\"valid\"),\n",
        "        # pooled to length 70\n",
        "      tf.keras.layers.Conv1D(filters=16,kernel_size=8,padding='same',activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPooling1D(7, padding=\"same\"),\n",
        "        # pooled to length 10\n",
        "    ])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv1D(filters=16,kernel_size=8,padding='same',activation=\"relu\"),\n",
        "      tf.keras.layers.UpSampling1D(7),\n",
        "      # upscaled to 70\n",
        "      tf.keras.layers.Conv1D(filters=16,kernel_size=32,activation=\"relu\",padding=\"same\"),\n",
        "      tf.keras.layers.UpSampling1D(2),\n",
        "      # upscalaed to 140\n",
        "      tf.keras.layers.Conv1D(filters=16,kernel_size=32,padding='same',activation=\"relu\"),\n",
        "      tf.keras.layers.Conv1D(filters=1,kernel_size=64,padding='same',activation=\"relu\"),\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = AnomalyDetector()\n",
        "autoencoder.compile(optimizer='adam', loss='mae')\n",
        "\n",
        "autoencoder.fit(normal_train_data_2d, normal_train_data_2d,\n",
        "          epochs=20,\n",
        "          batch_size=512,\n",
        "          validation_data=(valid_data_2d, valid_data_2d),\n",
        "          shuffle=True, callbacks=[tensorboard_callback,WandbMetricsLogger()])"
      ],
      "metadata": {
        "id": "YqnaLYSGJKyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Predictions"
      ],
      "metadata": {
        "id": "MEhP6YBGShbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data = autoencoder.encoder(normal_train_data_2d).numpy()\n",
        "decoded_data = autoencoder.decoder(encoded_data).numpy().reshape(-1,140)\n",
        "\n",
        "plt.plot(normal_valid_data[0], 'b')\n",
        "plt.plot(decoded_data[0], 'r')\n",
        "plt.fill_between(np.arange(140), decoded_data[0], normal_valid_data[0], color='lightcoral')\n",
        "plt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yEWOzel4MB6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data = autoencoder.encoder(anomalous_valid_data_2d).numpy()\n",
        "decoded_data = autoencoder.decoder(encoded_data).numpy().reshape(-1,140)\n",
        "\n",
        "plt.plot(anomalous_valid_data[0], 'b')\n",
        "plt.plot(decoded_data[0], 'r')\n",
        "plt.fill_between(np.arange(140), decoded_data[0], anomalous_valid_data[0], color='lightcoral')\n",
        "plt.legend(labels=[\"Input\", \"Reconstruction\", \"Error\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lmwzIPuyR916"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distributions of errors"
      ],
      "metadata": {
        "id": "rQ5ZtusvSkoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions = tf.squeeze(autoencoder.predict(normal_train_data_2d),2)\n",
        "train_loss = tf.keras.losses.mae(reconstructions, normal_train_data)\n",
        "\n",
        "plt.hist(train_loss[None,:], bins=50)\n",
        "plt.xlabel(\"Train loss\")\n",
        "plt.ylabel(\"No of examples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pSDGhCfXSmzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = np.mean(train_loss) + np.std(train_loss)\n",
        "print(\"Threshold: \", threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k32bagWTCwC",
        "outputId": "64d10331-6f48-4168-a504-6c915e2154ee"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold:  0.0334326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions = tf.squeeze(autoencoder.predict(anomalous_valid_data_2d),2)\n",
        "valid_loss = tf.keras.losses.mae(reconstructions, anomalous_valid_data)\n",
        "\n",
        "plt.hist(valid_loss[None, :], bins=50)\n",
        "plt.xlabel(\"Validation loss\")\n",
        "plt.ylabel(\"No of examples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BLKLBxvATGTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, data, threshold):\n",
        "  reconstructions = tf.squeeze(model(data),2)\n",
        "  loss = tf.keras.losses.mae(reconstructions, tf.squeeze(data,2))\n",
        "  return tf.math.less(loss, threshold)\n",
        "\n",
        "def print_stats(predictions, labels):\n",
        "  print(\"Accuracy = {}\".format(accuracy_score(labels, predictions)))\n",
        "  print(\"Precision = {}\".format(precision_score(labels, predictions)))\n",
        "  print(\"Recall = {}\".format(recall_score(labels, predictions)))"
      ],
      "metadata": {
        "id": "TullNMUQTbxJ"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = predict(autoencoder, valid_data_2d, threshold)\n",
        "print_stats(preds, valid_labels)"
      ],
      "metadata": {
        "id": "hCOVOv1FTXw9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}